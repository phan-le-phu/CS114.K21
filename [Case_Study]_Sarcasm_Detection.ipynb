{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of [Case_Study]_Sarcasm_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phan-le-phu/CS114.K21/blob/master/%5BCase_Study%5D_Sarcasm_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Tttdlf8xly",
        "colab_type": "text"
      },
      "source": [
        "Thành viên nhóm:\n",
        "- Phan Lê Phú (mssv: 18521247) \n",
        "- Trịnh Việt Hoàng (mssv: 17520522)\n",
        "- Nguyễn Đức Hoan (mssv: 17520501)\n",
        "\n",
        "Bài làm dưới đây của nhóm em dựa trên tài liệu tham khảo:\n",
        "https://towardsdatascience.com/sarcasm-detection-step-towards-sentiment-analysis-84cb013bb6db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjivrl94zgMo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# **Mô tả vấn đề**\n",
        "\n",
        "Trong những nghiên cứu trước đây hầu như đều sử dụng Twitter Dataset thu thập \n",
        "được nhờ quan sát hastag được gắn liền với tweet. Nhưng những dữ liệu như vậy \n",
        "thì xuất hiện sai sót khi dán nhãn hoặc gặp vấn đề về khác biệt ngôn ngữ. Hơn nữa những dòng tweet có thể reply những dòng tweet khác do đó chúng ta phải phải có cái nhìn toàn thể của ngữ cảnh mới có thể gán nhán chính xác cho tweet.\n",
        "\n",
        "Để vượt qua những hạn chế liên quan tới độ sai lệch của Twitter datasets, chúng tôi đề xuất sử dụng News Headlines dataset cho bài toán Sarcasm Detection đã được thu thập từ hai trang web. Trang wed TheOnion mục đích đăng tải các tin tức chấm biếm của các sự kiện hiện tại và chúng tôi đã thu thập tất cả headlines từ chuyên mục News in Brief và News in Photos(những headline châm biếm). Bên cạnh đó chúng tôi thu thập các headlines (những headline không châm biếm) từ các tin tức 'thời sự' trên trang HuffPost\n",
        "\n",
        "Sau đây là những điểm vượt trội của news dataset đối vơi Twitter datasets:\n",
        "- Vì những tin tức được viết bởi những người  viết tin chuyên nghiệp với một cách thức thống nhất do đó không có lối chính tả và văn phong chuẩn mực. Điều này làm giảm 'độ thưa thớt' và tăng cơ hội tìm được pre-trained embeddings.\n",
        "-Hơn nữa, mục đích chính của trang tin TheOnion là đăng tải những tin châm biếm\n",
        "vì thế chúng ta nhận được độ chính xác cao của các nhãn tướng ứng với headlines hơn khi so sánh với Twitter datasets.\n",
        "- Không như tweets có thể reply lại tweets khác, the news headlines chúng ta thu được thì chỉ có ý nghĩa đối với bài báo mà nó được xuất hiện cùng. Điều này giúp chúng ta nhìn nhận được các yếu tố châm biếm thực sự.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag5WNju91GW1",
        "colab_type": "text"
      },
      "source": [
        "## **Mô tả dataset**\n",
        "\n",
        "Dataset bao gồm ba cột:\n",
        "*   ```article_link``` (type: Object): chứa links dẫn đến news articles\n",
        "*   ```headline``` (type: Object): chứa headlines của news articles\n",
        "*   ```is_sarcastic``` (type: int64): giá trị 0 nếu thu thập từ trang HuffPost(không phải sarcastic) hoặc giá trị 1 nếu thu thập từ trang TheOnion(sarcastic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsTGGPXm14M1",
        "colab_type": "text"
      },
      "source": [
        "## **Source Code**\n",
        "\n",
        "Đầu tiên import các moudle cần thiết để xử lý bài toán.\n",
        "- moudle pandas cần cho việc đọc file json \n",
        "- moudle numpy\n",
        "- moudle regex\n",
        "- hàm PorterStemmer từ moulde nltk.stem.porter dùng để stem các từ trong câu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-zihh-v0-Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np, re, time\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBJSXCTi2b8p",
        "colab_type": "text"
      },
      "source": [
        "- Hàm train_test_split được import để chia dataset thành tập dữ liệu train và tập dữ liệu test\n",
        "- Vì đây là bài toán classification nên em import các model cài đặt thuật toán sử dụng được cho bài toán này. Mục tiêu là model nào cho kết quả thu được tốt nhất em sẽ chọn model đó để đánh giá với tập dữ liệu tự thu thập."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL3ld_B-1sQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3cJwF_m29G0",
        "colab_type": "text"
      },
      "source": [
        "- tải tập dataset đã tải từ kaggle lên colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3ZQ6RB0wuVv",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c560b3d9-c193-4232-c7ad-e482c7d39c39"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9e27e035-f1a7-4adc-bcac-6bd51f142a1e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9e27e035-f1a7-4adc-bcac-6bd51f142a1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Sarcasm_Headlines_Dataset_v2.json to Sarcasm_Headlines_Dataset_v2.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUPIbZaGaTeL",
        "colab_type": "text"
      },
      "source": [
        "- đọc file chứa dataset được tải lên bên trên bằng hàm read_json của module pandas thu được một DataFrame và dùng biến data để quản lý nó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQHcFBaJyZxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines = True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_XdlBe2UFX",
        "colab_type": "text"
      },
      "source": [
        "- Hiển thị bố cục của Dataframe được quản lý bởi biến data. Dễ thấy nó bao gồm ba cột(is_scarastic, headline và article_link) mỗi cột chứa các thông tin như đã được miêu tả trong phần mô tả dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11eDv2zJxIqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "41825652-bc1a-4504-da89-46fe317058dc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-CTWk1vewc0",
        "colab_type": "text"
      },
      "source": [
        "- dataset bao gồm 28619 examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC3_cfUHek0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc43bfd1-8ab7-4380-d897-2d4d49baf665"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28619, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vhwPEdE2ypL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- trong 28619 examples không có giá Null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ejE-kCtykm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "854d8198-5362-415b-8b50-0d2037a25423"
      },
      "source": [
        "print(data.isnull().any(axis = 0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_sarcastic    False\n",
            "headline        False\n",
            "article_link    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTJ_EnkSzBK_",
        "colab_type": "text"
      },
      "source": [
        "## **Cleaning the data**\n",
        "\n",
        "Cột headline có chứa một vài ký tự đặc biệt chúng ta không cần xét đến  ở đây đối với từng headline em chỉ xét đến các ký tự trong tập a-z và A-Z.\n",
        "- dòng code bên dưới sẽ loop qua từng phần tử trong headline column ứng với mỗi vòng lặp là một headline **s**. Chuỗi  **s** này sẽ được xử lý bằng hàm ẩn lambda. Trong hàm ẩn lambda sử dụng hàm sub của moulde re, hàm này sẽ thấy thế những ký tự match với biểu thức regex [^a-zA-Z] (những ký từ không trong tập a-z và A-Z sẽ match) bằng ký tự ' ' (1 lần space). Hàm ẩn sẽ trả về chuỗi mới sau khi được xử lý. Sau đó chuỗi này sẽ được thay thế vào index tương ứng của chuỗi **s** trong headline column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAz9WAIayuph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing special symbols and digits in headline column\n",
        "# Using Regular Expresion\n",
        "data['headline'] = data['headline'].apply(lambda s : re.sub('[^a-zA-Z]', ' ', s))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxySWnwQ3o_c",
        "colab_type": "text"
      },
      "source": [
        "## **Feature and label extractions**\n",
        "\n",
        "Như đã mô  tả bên trên dataset của chúng ta có 3 cột. Tuy nhiên, ```article_link``` thì không quan trọng đối với bài toán bởi vì không có thì cũng không ảnh hưởng tới mục tiêu bài toán việc nó được lưu trữ là để thuận tiện cho việc thu thập thêm dữ liệu sau này. Vì vậy chỉ có   ```headline```  là feature duy nhất. Và, ```is_sarcastic``` là label duy nhất của dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwvgvWr-zARL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting features and labels\n",
        "features = data['headline']\n",
        "labels = data['is_sarcastic']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74VVwhML4Yfq",
        "colab_type": "text"
      },
      "source": [
        "## **Stemming of features (tại sao phải làm bước này?)**\n",
        "\n",
        "Ở bước này ta chuyển các từ đã được biến đổi thành các từ gốc của nó.\n",
        "\n",
        "Ví dụ minh họa:\n",
        "\n",
        "*   original words: ```reading``` and ```reader```\n",
        "*   stemmed words: ```read```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq-tn4fhlyQL",
        "colab_type": "text"
      },
      "source": [
        "- dòng  code đầu tiên dùng biến ps để quản lý đối tượng PorterStemmer\n",
        "- dòng code tiếp theo sẽ loop qua từng chuỗi **x** trong dataframe(chứa cột headline) được quản lý bởi biến features. Chuỗi **x** sẽ được xử lý bằng hàm ẩn lambda. Hàm này sẽ cắt chuỗi thành các từ riêng biệt dựa vào yếu tố các từ được cách nhau bởi dấu cách và trả về kết quả là một mảng chứa các từ sau khi được cắt từ chuỗi **x**. Cuối cùng nó sẽ được lưu vào index tương ứng của chuỗi **x**\n",
        "trong dataframe được quản lý bởi biến features\n",
        "- dòng code cuối cùng loop qua từng mảng **x** trong dataframe(chứa cột headline) được quản lý bởi biến features. Mảng **x** sẽ được xử lý bằng hàm ẩn lambda. Hàm này sẽ loop qua từng phân tử trong mảng **x**, mỗi phần tử sẽ được xử lý bằng hàm ps.tem() đễ tìm từ gốc tương tứng của nó sau đó các phần tử sẽ được kết lại thành một mảng trở thành tham số trong hàm join, hàm join sẽ hợp các phần tử trong mảng vừa nhận thành một chuỗi và phân chia chúng bằng dấu cách, kết quả là ta thu được một chuỗi. Cuối cùng nó sẽ được lưu vào index tương ứng của mảng **x** trong dataframe được quản lý bởi biến features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DsbED2w6kcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming the data\n",
        "ps = PorterStemmer()\n",
        "\n",
        "features = features.apply(lambda x: x.split())\n",
        "features = features.apply(lambda x: ' '.join([ps.stem(word) for word in x]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T0BSdAwNdTQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## **Vectorization of features**\n",
        "\n",
        "Vì chúng ta không thể feed model bằng text do đó em sử dụng kỹ thuật sau để biểu diễn một đoạn text được nhận thành một vector 1 chiều có số features max là 5000 mỗi feature trong vector là chỉ số  TF-IDF của một từ bên trong đoạn text: ***TF-IDF (Term Frequency-Inverse Document Frequency)***.\n",
        "\n",
        "\n",
        "***TF - Term Frequency***: Xem xét tuần suất xuất hiện của một từ trong text. Có giá trị nằm trong khoảng  [0-1]. Nếu một từ trong text xuất hiện càng nhiều lần thì giá trị càng tiến về 1 và ngược lại\n",
        "\n",
        "***IDF - Inverse Document Frequency***: Xem xét tuần xuất xuất hiện của một từ trong corpus. Nều từ đó xuất hiện càng ít thì giá trị càng lớn và ngược lại.\n",
        "[Link tham khảo](https://vi.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMz5OUYjIkkz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   import class TfidfVectorizer từ moulde sklearn và dùng biến tv để quản lý nó\n",
        "*   cài đặt max_feaures  cho data bằng 5000\n",
        "*   convert dataframe thành list\n",
        "*   sử dụng hàm fit_tranform  với tham số là một list chứa các headlines. Sau  khi thực hiện nó sẽ trả về một csr.matrix. Khi dùng hàm print  với tham số là nó, thì sẽ hiện thị nhiều dòng. Mỗi dòng sẽ có cấu trúc '(a, b)    data'. Trong đó a là index của text trong list features, b là index của từ đó trong tập set(tập set là một tập chứa các từ vựng được tìm thấy trong list features và được sắp xếp theo bảng chữ cái), data là chỉ số if-idf tương ứng.\n",
        "*    hàm toarray sẽ chuyển csr.matrix bên trên thành một ndarray chứ một tập các vector biểu diễn ý nghĩa bằng số cho text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK3xVzUHNUpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizing the data with maximum of 5000 features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tv = TfidfVectorizer(max_features = 5000)\n",
        "features = list(features)\n",
        "headlines = tv.fit_transform(features).toarray()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N79eFOFaRTui",
        "colab_type": "text"
      },
      "source": [
        "## **Training and Testing data**\n",
        "\n",
        "* dùng hàm train_test_split với các tham số là features( cột headlines), labels(cột is_sarcastic), test_size=0.05 (5% cho dữ liệu test), random_state=0 và dùng các biến tương ứng với tên của nó bên dưỡi để quản lý."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uEmw-42RiSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting training and testing dataset\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(headlines, labels, test_size = .05, random_state = 0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMydtmOMRi1a",
        "colab_type": "text"
      },
      "source": [
        "## **Training and Testing of models**\n",
        "\n",
        "Train các loại model khác nhau bằng cách sử dụng nhiều thuật toán máy học.\n",
        "1.   Linear Support Vector Classifier\n",
        "2.   Gaussian Naive Bayes\n",
        "3.   Logistic Regression\n",
        "4.   Random Forest Classifier\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pm0nFEvRSpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fcfd9ed0-2bf3-4e98-cc05-5a267815a8fd"
      },
      "source": [
        "# Model 1: Linear Support Vector Classifier\n",
        "\n",
        "lsvc = LinearSVC()\n",
        "\n",
        "# Training the model\n",
        "lsvc.fit(features_train, labels_train)\n",
        "\n",
        "# Getting the score of train and test data\n",
        "print(lsvc.score(features_train, labels_train))\n",
        "print(lsvc.score(features_test, labels_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9069074591731646\n",
            "0.8322851153039832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbWPXf5LTaYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "64bd6bad-0cff-4edf-b17b-5c28566afb10"
      },
      "source": [
        "# Model 2: Gaussian Naive Bayes\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Training the model\n",
        "gnb.fit(features_train, labels_train)\n",
        "\n",
        "# Getting the score of train and test data\n",
        "print(gnb.score(features_train, labels_train))\n",
        "print(gnb.score(features_test, labels_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7977416507282624\n",
            "0.7169811320754716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6d7UYuBUGTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "03112d0b-0bb6-4cd9-a1c2-f02ecf9a58a9"
      },
      "source": [
        "# Model 3: Logistic Regression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Training the model\n",
        "lr.fit(features_train, labels_train)\n",
        "\n",
        "# Getting the score of train and test data\n",
        "print(lr.score(features_train, labels_train))\n",
        "print(lr.score(features_test, labels_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8778137413564808\n",
            "0.8252969951083159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHbRyzgHUGaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0e8ad298-b509-4cfd-82f0-3c9bbb5e6640"
      },
      "source": [
        "# Model 4: Random Forest Classifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators= 10, random_state= 0)\n",
        "\n",
        "# Training the model\n",
        "rfc.fit(features_train, labels_train)\n",
        "\n",
        "# Getting the score of train and test data\n",
        "print(rfc.score(features_train, labels_train))\n",
        "print(rfc.score(features_test, labels_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9883404443136677\n",
            "0.7721872816212438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEptG9l6RbD7",
        "colab_type": "text"
      },
      "source": [
        "Nhận thấy model sử dụng thuật toán linear support vector classifier cho điểm score cao trên cả train dataset và test dataset khi so với các model sử dụng các thuật toán khác. Model số 4 sử dụng thuật toán random forest classifer mặc dù cho điểm score rất cao với train dataset những lại khá là thập trong tập test dataset đây có thể là dấu hiêu của model đã bị overfit. Do đó em chọn model sử dụng thuật toán support vector classifier làm model để thực hiện các bước tiếp theo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0vMQ4mwTlVr",
        "colab_type": "text"
      },
      "source": [
        "## **Ứng dụng model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r64sGjVyj8aN",
        "colab_type": "text"
      },
      "source": [
        "- Yêu cầu người dùng nhập headline cần detect\n",
        "- clean headline và stem word  cho headline tương tự với các bác đã thực hiên cho dataset\n",
        "- thêm headline và list các text của dataset được quản lý bới biến features sau đó biểu diễn  ý nghĩa của headline bằng 1 vecor có max 5000 features\n",
        "- sau đó tiến hành predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD_swJMfVM3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "23af2892-9394-415d-d009-9498c585d944"
      },
      "source": [
        "print(\"Nhập headline cần detect:\")\n",
        "headline = input()\n",
        "\n",
        "headline = re.sub('[^a-zA-Z]', ' ', headline)\n",
        "\n",
        "headline = ' '.join([ps.stem(word) for word in headline.split()])\n",
        "\n",
        "features.append(headline)\n",
        "\n",
        "tv = TfidfVectorizer(max_features=5000)\n",
        "headline = tv.fit_transform(features).toarray()[-1].reshape(1,-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Đang xử lý.......\")\n",
        "if rfc.predict(headline)[0] == 1:\n",
        "  print(\"Đây là headline của tin tức châm biếm!!!\")\n",
        "else:\n",
        "    print(\"Đây là headline của tin tức thời sự!!!\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nhập headline cần detect:\n",
            "Nancy Pelosi Calls Jamaal Bowman To Scold Him For Winning Primary\n",
            "Đang xử lý.......\n",
            "Đây là headline của tin tức thời sự!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxiIBH6woLOY",
        "colab_type": "text"
      },
      "source": [
        "## **Kiểm tra kết quả của model với dataset tự thu thập được**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-38Z82porXh",
        "colab_type": "text"
      },
      "source": [
        "Đọc file csv của datasets thu thập được bằng hàm read_csv của thư viện pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3O8p_SUpfxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onion_dataset = pd.read_csv(\"https://raw.githubusercontent.com/phan-le-phu/CS114.K21/master/collection_dataset_for_sarcasm_detection/onion_titles.csv\")\n",
        "huffpost_dataset = pd.read_csv(\"https://raw.githubusercontent.com/phan-le-phu/CS114.K21/master/collection_dataset_for_sarcasm_detection/huffpost_tittles.csv\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU8YYbOEsnTN",
        "colab_type": "text"
      },
      "source": [
        "Mỗi dataframe thu được có bốn cột trong đó cột đầu tiên là cột index, cột thứ hai là cột is_sarcastic, cột thứ ba là headline và cột cuối cùng là article_link.\n",
        "Trong tập dataset của onion có 1506 headline còn trong tập dataset của huffpost chứa 1008 headline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-CZ8MQSsTaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0f8bdd10-52ca-4aa1-e2d7-fe40c0c594bb"
      },
      "source": [
        "print(onion_dataset.shape)\n",
        "print(huffpost_dataset.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1506, 4)\n",
            "(1008, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOsiCNSu1Mty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "87c6f873-4c3e-4de4-d9fb-89d077f034f6"
      },
      "source": [
        "print(huffpost_dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0  ...                                       article_link\n",
            "0              0  ...  https://www.huffpost.com/entry/hickenlooper-co...\n",
            "1              1  ...  https://www.huffpost.com/entry/genderfluid-com...\n",
            "2              2  ...  https://www.huffpost.com/entry/ibm-facial-reco...\n",
            "3              3  ...  https://www.huffpost.com/entry/sophie-turner-s...\n",
            "4              4  ...  https://www.huffpost.com/entry/eliot-engel-hot...\n",
            "...          ...  ...                                                ...\n",
            "1003        1003  ...  https://www.huffpost.com/entry/george-w-bush-g...\n",
            "1004        1004  ...  https://www.huffpost.com/entry/street-art-blac...\n",
            "1005        1005  ...  https://www.huffpost.com/entry/amc-theatres-re...\n",
            "1006        1006  ...  https://www.huffpost.com/entry/temecula-califo...\n",
            "1007        1007  ...  https://www.huffpost.com/entry/gop-sheriff-cor...\n",
            "\n",
            "[1008 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U3aMR-ytZe7",
        "colab_type": "text"
      },
      "source": [
        "Chuẩn bị dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fEQny1AugmH",
        "colab_type": "text"
      },
      "source": [
        "- liên kết hai dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzyK9rVIti_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f6ec2801-7a73-4d32-fdf9-fd4a8bc6b5dc"
      },
      "source": [
        "new_data = onion_dataset.append(huffpost_dataset)\n",
        "print(new_data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0  ...                                       article_link\n",
            "0              0  ...  https://www.theonion.com/mental-health-experts...\n",
            "1              1  ...  https://www.theonion.com/the-onion-s-father-s-...\n",
            "2              2  ...  https://sports.theonion.com/staples-center-emp...\n",
            "3              3  ...  https://www.theonion.com/father-s-day-gifts-th...\n",
            "4              4  ...  https://www.theonion.com/huh-boyfriend-s-ex-ju...\n",
            "...          ...  ...                                                ...\n",
            "1003        1003  ...  https://www.huffpost.com/entry/george-w-bush-g...\n",
            "1004        1004  ...  https://www.huffpost.com/entry/street-art-blac...\n",
            "1005        1005  ...  https://www.huffpost.com/entry/amc-theatres-re...\n",
            "1006        1006  ...  https://www.huffpost.com/entry/temecula-califo...\n",
            "1007        1007  ...  https://www.huffpost.com/entry/gop-sheriff-cor...\n",
            "\n",
            "[2514 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f7TW-BgyyMk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbaOLMLjx5KE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8302ee65-eef2-4470-c1a8-4eb2322d5334"
      },
      "source": [
        "print(new_data.isnull().any(axis = 0))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0      False\n",
            "is_sarcastic    False\n",
            "titles          False\n",
            "article_link    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjFFpyz80YSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_features = new_data[\"titles\"]\n",
        "new_labels = new_data[\"is_sarcastic\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L19JyI4wyl-",
        "colab_type": "text"
      },
      "source": [
        "Xử lý dataset tương tự như vơi cách xử lý bên trên"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6TWhavHwoOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing special symbols and digits in headline column\n",
        "# Using Regular Expresion\n",
        "new_features = new_features.apply(lambda s : re.sub('[^a-zA-Z]', ' ', s))\n",
        "\n",
        "# Stemming the data\n",
        "ps = PorterStemmer()\n",
        "\n",
        "new_features = new_features.apply(lambda x: x.split())\n",
        "new_features = new_features.apply(lambda x: ' '.join([ps.stem(word) for word in x]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rYvdDjMwLiW",
        "colab_type": "text"
      },
      "source": [
        "- lấy index from để xác định khoảng các text cần kiểm tra\n",
        "- thêm các headline mới vào tập các headline cũ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXR4t6SmufgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from_index = len(features)\n",
        "\n",
        "features += list(new_features)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTVkZk252rBq",
        "colab_type": "text"
      },
      "source": [
        "- Biểu diễn các healine trong tập dataset mới bằng các vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPPzd5yy21Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizing the data with maximum of 5000 features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tv = TfidfVectorizer(max_features = 5000)\n",
        "new_headlines = tv.fit_transform(features).toarray()[from_index:]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLQZoyLR43CS",
        "colab_type": "text"
      },
      "source": [
        "- Sử dụng model với tập dataset vừa thu thập được."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX8OB4094-or",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20cf8cba-02c9-4986-f9da-2eb710f3ed41"
      },
      "source": [
        "print(lsvc.score(new_headlines, new_labels))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5095465393794749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJw0rcAP7EYZ",
        "colab_type": "text"
      },
      "source": [
        "## **Nhận xét kết quả**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWWRd8TN7Kin",
        "colab_type": "text"
      },
      "source": [
        "Kết quả thu được đối với tập dataset mới của model chỉ được 0.50597 khá là thấp so với kết quả kiểm nghiêm của model trên train dataset và test dataset. Em dự đoán một vài nguyên nhân sau.\n",
        "- có thể model bị overfit với train dataset do kêt quả thu được của model khá cao là 0.90 nhưng test dataset thu được thì thấp hơn là  0.83.\n",
        "- dữ liệu huấn luyến chưa đủ nhiều để train model\n",
        "- bước features engneering chữa biểu diễn được chính xác ý nghĩa của câu bằng số."
      ]
    }
  ]
}